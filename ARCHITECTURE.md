# ðŸ—ï¸ ARQUITECTURA DEL PROYECTO SPACEFLIGHTS

## ðŸ“‹ Tabla de Contenidos
1. [Vista General](#vista-general)
2. [Componentes Principales](#componentes-principales)
3. [Flujo de Datos](#flujo-de-datos)
4. [Arquitectura Docker](#arquitectura-docker)
5. [IntegraciÃ³n Airflow-Kedro](#integraciÃ³n-airflow-kedro)
6. [Estructura de Directorios](#estructura-de-directorios)
7. [Decisiones de DiseÃ±o](#decisiones-de-diseÃ±o)

---

## ðŸŽ¯ Vista General

Spaceflights es un proyecto de ejemplo que demuestra un pipeline de Machine Learning end-to-end usando:
- **Kedro**: Framework de pipeline de datos
- **Docker**: ContainerizaciÃ³n y consistencia de entornos
- **Apache Airflow**: OrquestaciÃ³n y scheduling
- **DVC**: Versionado de datos (parcial)
- **PostgreSQL**: Almacenamiento de datos (opcional)
- **Redis**: Cache (opcional)

```mermaid
graph TB
    subgraph "Data Sources"
        A[Raw Data CSV/Excel]
    end
    
    subgraph "Kedro Pipelines"
        B[Data Processing]
        C[Data Science]
        D[Reporting]
    end
    
    subgraph "Orchestration"
        E[Airflow DAGs]
        F[Kedro Scheduler]
    end
    
    subgraph "Storage"
        G[Data Versioning]
        H[Model Registry]
        I[PostgreSQL]
    end
    
    subgraph "Visualization"
        J[Kedro Viz]
        K[JupyterLab]
        L[Plotly Reports]
    end
    
    A --> B
    B --> C
    C --> D
    D --> L
    
    E -.-> B
    E -.-> C
    E -.-> D
    
    F -.-> B
    F -.-> C
    F -.-> D
    
    B --> G
    C --> H
    
    J --> B
    J --> C
    J --> D
    
    K --> B
    K --> C
    K --> D
```

---

## ðŸ§© Componentes Principales

### 1. Kedro (Core ML Pipeline)

**PropÃ³sito**: Framework para crear pipelines de datos reproducibles y mantenibles.

**Pipelines**:
- **data_processing**: Preprocesamiento de datos raw
  - Limpieza de datos
  - Transformaciones
  - Feature engineering inicial
  
- **data_science**: Entrenamiento y evaluaciÃ³n de modelos
  - Split de datos
  - Entrenamiento de regressor
  - EvaluaciÃ³n de mÃ©tricas
  
- **reporting**: GeneraciÃ³n de visualizaciones y reportes
  - GrÃ¡ficos de capacidad de pasajeros
  - Matriz de confusiÃ³n
  - ExportaciÃ³n de resultados

**Data Catalog**: Gestiona inputs/outputs de datasets
- CSV, Excel, Parquet
- Pickle para modelos
- JSON para visualizaciones
- Versionado automÃ¡tico

### 2. Docker (ContainerizaciÃ³n)

**ImÃ¡genes**:

#### Dockerfile.kedro
```
Base: python:3.11-slim
PropÃ³sito: EjecuciÃ³n de pipelines Kedro
Servicios: kedro-prod, kedro-scheduler, kedro-viz
```

#### Dockerfile.jupyter
```
Base: python:3.11-slim
PropÃ³sito: Desarrollo interactivo
Servicios: jupyter-lab
Extras: jupyterlab-git, LSP, plotly
```

#### Dockerfile.airflow
```
Base: apache/airflow:2.8.0-python3.11
PropÃ³sito: OrquestaciÃ³n con Airflow
Servicios: airflow-webserver, airflow-scheduler, airflow-init
```

### 3. Apache Airflow (OrquestaciÃ³n)

**Componentes**:
- **Webserver**: UI para gestionar DAGs
- **Scheduler**: Ejecuta DAGs segÃºn schedule
- **PostgreSQL**: Metastore de Airflow
- **Redis**: Message broker (opcional para Celery)

**DAGs**:
- `spaceflights_dag.py`: Pipeline completo
- `spaceflights_data_processing_dag.py`: Solo procesamiento
- `spaceflights_reporting_dag.py`: Solo reportes

**KedroOperator**: Operador custom para ejecutar nodos de Kedro desde Airflow

### 4. Bases de Datos

#### PostgreSQL (Kedro - Opcional)
```
Puerto: 5433 (para evitar conflicto con instalaciÃ³n local)
Database: spaceflights
Usuario: kedro
```

#### PostgreSQL (Airflow - Requerido)
```
Puerto: 5432 (interno)
Database: airflow
Usuario: airflow
PropÃ³sito: Metastore de Airflow
```

### 5. VisualizaciÃ³n

#### Kedro Viz
```
Puerto: 4141
PropÃ³sito: Visualizar estructura de pipelines
Features: DAG visualization, data flow
```

#### JupyterLab
```
Puerto: 8888
PropÃ³sito: Desarrollo interactivo
Features: Notebooks, terminal, file browser
```

---

## ðŸ”„ Flujo de Datos

### Flujo Completo del Pipeline

```mermaid
sequenceDiagram
    participant Raw as Raw Data
    participant DP as Data Processing
    participant DS as Data Science
    participant Rep as Reporting
    participant Store as Storage
    
    Raw->>DP: companies.csv, reviews.csv, shuttles.xlsx
    
    DP->>DP: preprocess_companies
    DP->>DP: preprocess_shuttles
    DP->>Store: preprocessed_companies.parquet
    DP->>Store: preprocessed_shuttles.parquet
    
    Store->>DS: preprocessed data
    DS->>DS: create_model_input_table
    DS->>DS: split_data
    DS->>DS: train_model
    DS->>DS: evaluate_model
    DS->>Store: regressor.pickle (versioned)
    
    Store->>Rep: model + preprocessed data
    Rep->>Rep: generate_plots
    Rep->>Store: plotly charts (versioned)
    Rep->>Store: confusion_matrix.png (versioned)
```

### Data Layers (Kedro Data Engineering Convention)

```
data/
â”œâ”€â”€ 01_raw/              # Datos originales, inmutables
â”‚   â”œâ”€â”€ companies.csv
â”‚   â”œâ”€â”€ reviews.csv
â”‚   â””â”€â”€ shuttles.xlsx
â”‚
â”œâ”€â”€ 02_intermediate/     # Datos procesados intermedios
â”‚   â”œâ”€â”€ preprocessed_companies.parquet
â”‚   â””â”€â”€ preprocessed_shuttles.parquet
â”‚
â”œâ”€â”€ 03_primary/          # Tablas principales para modelado
â”‚   â””â”€â”€ model_input_table.parquet
â”‚
â”œâ”€â”€ 04_feature/          # Features engineered (si aplica)
â”‚
â”œâ”€â”€ 05_model_input/      # Datos listos para modelo
â”‚
â”œâ”€â”€ 06_models/           # Modelos entrenados
â”‚   â””â”€â”€ regressor.pickle/
â”‚       â””â”€â”€ <timestamp>/
â”‚
â”œâ”€â”€ 07_model_output/     # Predicciones (si aplica)
â”‚
â””â”€â”€ 08_reporting/        # Reportes y visualizaciones
    â”œâ”€â”€ shuttle_passenger_capacity_plot_exp.json/
    â”œâ”€â”€ shuttle_passenger_capacity_plot_go.json/
    â””â”€â”€ dummy_confusion_matrix.png/
```

---

## ðŸ³ Arquitectura Docker

### Networking

```mermaid
graph TB
    subgraph "spaceflights-network"
        subgraph "Development Profile"
            JL[jupyter-lab:8888]
            KV[kedro-viz:4141]
        end
        
        subgraph "Production Profile"
            KP[kedro-prod]
            KS[kedro-scheduler]
        end
        
        subgraph "Database Profile"
            PG[(postgres:5433)]
        end
        
        subgraph "Cache Profile"
            RD[(redis:6379)]
        end
        
        subgraph "Airflow (separate compose)"
            AW[airflow-webserver:8080]
            AS[airflow-scheduler]
            AP[(airflow-postgres:5432)]
            AR[(airflow-redis)]
        end
    end
    
    JL -.-> PG
    KP -.-> PG
    
    AW --> AP
    AS --> AP
    AW -.-> AR
```

### Profiles Docker Compose

**docker-compose.yml**:
```yaml
Profiles:
  - development:  jupyter-lab, kedro-viz
  - production:   kedro-prod, kedro-scheduler, kedro-viz
  - database:     postgres
  - cache:        redis
  - monitoring:   prometheus
```

**docker-compose.airflow.yml**:
```yaml
Services (sin profiles):
  - airflow-postgres
  - airflow-redis
  - airflow-init
  - airflow-webserver
  - airflow-scheduler
```

### VolÃºmenes Persistentes

```yaml
Volumes:
  # CÃ³digo y configuraciÃ³n (bind mounts)
  - ./src:/app/src
  - ./conf:/app/conf
  - ./notebooks:/app/notebooks
  
  # Datos persistentes
  - ./data:/app/data
  - ./logs:/app/logs
  - ./sessions:/app/sessions
  
  # Bases de datos (volumes)
  - postgres_data:/var/lib/postgresql/data
  - redis_data:/data
  - airflow_postgres_data:/var/lib/postgresql/data
```

---

## ðŸ”— IntegraciÃ³n Airflow-Kedro

### KedroOperator

```python
class KedroOperator(BaseOperator):
    """
    Operador custom para ejecutar nodos de Kedro desde Airflow
    """
    def __init__(
        self,
        package_name: str,      # spaceflights
        pipeline_name: str,     # data_processing, data_science, etc.
        node_name: str,         # nombre del nodo especÃ­fico
        project_path: Path,     # /app
        env: str,               # local, production
        conf_source: str,       # path a conf/
    )
```

### Flujo de EjecuciÃ³n Airflow

```mermaid
sequenceDiagram
    participant User
    participant AW as Airflow Web
    participant AS as Airflow Scheduler
    participant KO as KedroOperator
    participant KS as Kedro Session
    participant Pipeline
    
    User->>AW: Activar DAG
    AW->>AS: Schedule task
    AS->>KO: Execute task
    KO->>KS: Create session
    KS->>Pipeline: Run specific node
    Pipeline->>Pipeline: Process data
    Pipeline-->>KS: Return result
    KS-->>KO: Session complete
    KO-->>AS: Task success
    AS-->>AW: Update status
    AW-->>User: Show result
```

### Mapping DAG â†” Kedro Pipeline

**Airflow DAG**:
```python
tasks = {
    "preprocess-companies": KedroOperator(
        node_name="preprocess_companies_node",
        pipeline_name="__default__"
    ),
    "preprocess-shuttles": KedroOperator(
        node_name="preprocess_shuttles_node",
        pipeline_name="__default__"
    )
}

tasks["preprocess-companies"] >> tasks["create-model-input"]
tasks["preprocess-shuttles"] >> tasks["create-model-input"]
```

**Kedro Pipeline** (equivalente):
```python
pipeline([
    node(preprocess_companies, ...),
    node(preprocess_shuttles, ...),
    node(create_model_input_table, ...)
])
```

---

## ðŸ“ Estructura de Directorios

```
spaceflights/
â”‚
â”œâ”€â”€ conf/                           # Configuraciones por entorno
â”‚   â”œâ”€â”€ base/                       # Config base (todos los entornos)
â”‚   â”‚   â”œâ”€â”€ catalog.yml            # Data catalog
â”‚   â”‚   â”œâ”€â”€ parameters*.yml        # ParÃ¡metros de pipelines
â”‚   â”‚   â””â”€â”€ logging.yml            # Config de logging
â”‚   â”œâ”€â”€ local/                      # Config desarrollo local
â”‚   â”‚   â”œâ”€â”€ credentials.yml        # Credenciales (gitignored)
â”‚   â”‚   â””â”€â”€ airflow.yml
â”‚   â”œâ”€â”€ production/                 # Config producciÃ³n
â”‚   â”‚   â””â”€â”€ parameters.yml
â”‚   â””â”€â”€ airflow/                    # Config especÃ­fica Airflow
â”‚       â””â”€â”€ catalog.yml
â”‚
â”œâ”€â”€ data/                           # Datos (gitignored, excepto 01_raw)
â”‚   â”œâ”€â”€ 01_raw/                    # Datos raw
â”‚   â”œâ”€â”€ 02_intermediate/           # Datos procesados
â”‚   â”œâ”€â”€ 03_primary/                # Datos primarios
â”‚   â”œâ”€â”€ 06_models/                 # Modelos (versioned)
â”‚   â””â”€â”€ 08_reporting/              # Reportes (versioned)
â”‚
â”œâ”€â”€ dags/                           # DAGs de Airflow
â”‚   â”œâ”€â”€ spaceflights_dag.py
â”‚   â”œâ”€â”€ spaceflights_data_processing_dag.py
â”‚   â””â”€â”€ spaceflights_reporting_dag.py
â”‚
â”œâ”€â”€ docker/                         # Dockerfiles
â”‚   â”œâ”€â”€ Dockerfile.kedro
â”‚   â”œâ”€â”€ Dockerfile.jupyter
â”‚   â””â”€â”€ Dockerfile.airflow
â”‚
â”œâ”€â”€ docs/                           # DocumentaciÃ³n Sphinx
â”‚   â””â”€â”€ source/
â”‚
â”œâ”€â”€ notebooks/                      # Jupyter notebooks
â”‚   â””â”€â”€ ejemplo.ipynb
â”‚
â”œâ”€â”€ scripts/                        # Scripts de utilidad
â”‚   â”œâ”€â”€ start-dev.sh
â”‚   â”œâ”€â”€ start-prod.sh
â”‚   â”œâ”€â”€ run-pipeline.sh
â”‚   â”œâ”€â”€ monitor.sh
â”‚   â”œâ”€â”€ init-data.sh
â”‚   â”œâ”€â”€ init-db.sql
â”‚   â””â”€â”€ db-manage.sh
â”‚
â”œâ”€â”€ src/spaceflights/              # CÃ³digo fuente Python
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ __main__.py
â”‚   â”œâ”€â”€ pipeline_registry.py       # Registro de pipelines
â”‚   â”œâ”€â”€ settings.py                # Settings de Kedro
â”‚   â””â”€â”€ pipelines/                 # Pipelines modulares
â”‚       â”œâ”€â”€ data_processing/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ nodes.py          # Funciones de procesamiento
â”‚       â”‚   â””â”€â”€ pipeline.py       # DefiniciÃ³n del pipeline
â”‚       â”œâ”€â”€ data_science/
â”‚       â”‚   â”œâ”€â”€ nodes.py          # Funciones de ML
â”‚       â”‚   â””â”€â”€ pipeline.py
â”‚       â””â”€â”€ reporting/
â”‚           â”œâ”€â”€ nodes.py          # Funciones de visualizaciÃ³n
â”‚           â””â”€â”€ pipeline.py
â”‚
â”œâ”€â”€ tests/                          # Tests
â”‚   â”œâ”€â”€ test_run.py
â”‚   â””â”€â”€ pipelines/
â”‚
â”œâ”€â”€ docker-compose.yml              # Compose principal
â”œâ”€â”€ docker-compose.airflow.yml      # Compose Airflow
â”œâ”€â”€ docker-compose.override.yml     # Overrides locales (gitignored)
â”‚
â”œâ”€â”€ pyproject.toml                  # Config del proyecto
â”œâ”€â”€ requirements.txt                # Dependencias Python
â”œâ”€â”€ start.sh                        # Script de inicio rÃ¡pido
â”œâ”€â”€ env.example                     # Template de variables de entorno
â””â”€â”€ .env                            # Variables de entorno (gitignored)
```

---

## ðŸŽ¨ Decisiones de DiseÃ±o

### 1. Â¿Por quÃ© Kedro?

**Ventajas**:
- âœ… Pipelines modulares y reutilizables
- âœ… Data catalog abstrae sources/sinks
- âœ… ConfiguraciÃ³n por entorno
- âœ… Versionado automÃ¡tico de datasets
- âœ… FÃ¡cil testing de nodos individuales
- âœ… IntegraciÃ³n con mÃºltiples orquestadores

**Trade-offs**:
- âš ï¸ Curva de aprendizaje inicial
- âš ï¸ Overhead para proyectos muy simples

### 2. Â¿Por quÃ© Docker?

**Ventajas**:
- âœ… Entornos reproducibles
- âœ… Funciona igual en desarrollo y producciÃ³n
- âœ… Facilita onboarding de nuevos miembros
- âœ… Aislamiento de dependencias
- âœ… Escalabilidad horizontal

**Trade-offs**:
- âš ï¸ Overhead de recursos
- âš ï¸ Complejidad adicional inicial

### 3. Â¿Por quÃ© Airflow?

**Ventajas**:
- âœ… OrquestaciÃ³n robusta y escalable
- âœ… UI para monitoreo
- âœ… Retry logic y error handling
- âœ… Scheduling flexible
- âœ… Extensible con custom operators

**Trade-offs**:
- âš ï¸ Infraestructura pesada para proyectos simples
- âš ï¸ Requiere PostgreSQL para producciÃ³n

**Alternativas consideradas**:
- Prefect (mÃ¡s moderno, menos maduro)
- Dagster (buena integraciÃ³n con data, menos adopciÃ³n)
- Cronjobs simples (no escalables)

### 4. SeparaciÃ³n de Docker Composes

**DecisiÃ³n**: `docker-compose.yml` (Kedro) separado de `docker-compose.airflow.yml`

**RazÃ³n**:
- Kedro puede funcionar sin Airflow (desarrollo local)
- Airflow es opcional para estudiantes
- Facilita troubleshooting
- Permite usar diferentes backends de orquestaciÃ³n

### 5. Versionado de Modelos y Reportes

**ImplementaciÃ³n**: Kedro datasets con `versioned: true`

**Ventajas**:
- âœ… Trazabilidad completa
- âœ… Rollback fÃ¡cil
- âœ… ComparaciÃ³n de resultados entre ejecuciones

**Storage**:
```
data/06_models/regressor.pickle/
â””â”€â”€ 2025-10-02T22.36.54.243Z/
    â””â”€â”€ regressor.pickle
```

### 6. Puerto 5433 para PostgreSQL

**DecisiÃ³n**: Usar puerto 5433 en lugar de 5432

**RazÃ³n**:
- Evitar conflicto con PostgreSQL instalado localmente
- Facilitar desarrollo en mÃ¡quinas de estudiantes
- Dos instancias PostgreSQL: Kedro (5433) y Airflow (5432 interno)

### 7. Usuario No-Root en Contenedores

**ImplementaciÃ³n**: Usuario `kedro` en contenedores

**RazÃ³n**:
- âœ… Seguridad (principio de mÃ­nimo privilegio)
- âœ… Mejores prÃ¡cticas Docker
- âš ï¸ Puede causar problemas de permisos con bind mounts

---

## ðŸ” Consideraciones de Seguridad

### Secrets Management

**Desarrollo**:
- Variables en `.env` (gitignored)
- `env.example` como template

**ProducciÃ³n** (recomendaciones):
- Usar Docker Secrets
- Vault de HashiCorp
- AWS Secrets Manager / GCP Secret Manager
- Kubernetes Secrets

### Network Isolation

```
spaceflights-network (bridge)
â”œâ”€â”€ Servicios Kedro
â”œâ”€â”€ Servicios Airflow
â””â”€â”€ Bases de datos

No expuesto al exterior excepto:
- JupyterLab: 8888
- Kedro Viz: 4141
- Airflow UI: 8080
- PostgreSQL (opcional): 5433
```

### Least Privilege

- Usuarios no-root en contenedores
- Read-only volumes donde sea posible
- Health checks para detectar problemas

---

## ðŸ“Š Flujos de Trabajo

### Desarrollo Local

```mermaid
graph LR
    A[Clonar Repo] --> B[./start.sh development]
    B --> C[Abrir JupyterLab]
    C --> D[Desarrollar en Notebooks]
    D --> E[Convertir a Nodes]
    E --> F[Agregar a Pipeline]
    F --> G[Test con kedro run]
    G --> H[Ver en Kedro Viz]
    H --> I{Â¿OK?}
    I -->|No| D
    I -->|SÃ­| J[Commit & Push]
```

### ProducciÃ³n con Airflow

```mermaid
graph LR
    A[./start.sh airflow] --> B[Abrir Airflow UI]
    B --> C[Activar DAG]
    C --> D[Scheduler ejecuta]
    D --> E[KedroOperator llama Kedro]
    E --> F[Pipeline ejecuta]
    F --> G[Resultados en data/]
    G --> H[Ver en Kedro Viz]
    H --> I[Monitorear logs]
```

### CI/CD (futuro)

```mermaid
graph LR
    A[Git Push] --> B[GitHub Actions]
    B --> C[Run Tests]
    C --> D[Lint Code]
    D --> E[Build Docker Images]
    E --> F[Push to Registry]
    F --> G[Deploy to Production]
    G --> H[Health Check]
```

---

## ðŸŽ“ Valor Educativo

### Conceptos Cubiertos

1. **MLOps**:
   - Pipeline de ML end-to-end
   - Reproducibilidad
   - Versionado de modelos
   - OrquestaciÃ³n

2. **DevOps**:
   - ContainerizaciÃ³n
   - Infrastructure as Code
   - Environment management
   - Deployment automation

3. **Data Engineering**:
   - Data pipelines
   - Data versioning
   - Data catalog
   - ETL/ELT patterns

4. **Software Engineering**:
   - ModularizaciÃ³n
   - Testing
   - Configuration management
   - Documentation

---

## ðŸ“š Referencias

- [Kedro Documentation](https://docs.kedro.org/)
- [Apache Airflow Documentation](https://airflow.apache.org/docs/)
- [Docker Documentation](https://docs.docker.com/)
- [Docker Compose Reference](https://docs.docker.com/compose/)
- [DVC Documentation](https://dvc.org/doc)

---

**Ãšltima actualizaciÃ³n**: 2025-10-09
**VersiÃ³n**: 1.0

